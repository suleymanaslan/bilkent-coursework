{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_ix == 0:\n",
    "    nndr_threshold = 0.35\n",
    "    step_size = 0.001\n",
    "    residual_stopping_threshold = 0.1\n",
    "    img_list = [cv2.imread(\"dataset/data_image_stitching/im1.png\"),\n",
    "                cv2.imread(\"dataset/data_image_stitching/im2.png\")]\n",
    "\n",
    "elif data_ix == 1:\n",
    "    nndr_threshold = 0.40\n",
    "    step_size = 0.001\n",
    "    residual_stopping_threshold = 10\n",
    "    img_list = [cv2.imread(\"dataset/data_image_stitching/im22.jpg\"),\n",
    "                cv2.imread(\"dataset/data_image_stitching/im23.jpg\")]\n",
    "\n",
    "elif data_ix == 2:\n",
    "    nndr_threshold = 0.25\n",
    "    step_size = 0.001\n",
    "    residual_stopping_threshold = 0.1\n",
    "    img_list = [cv2.imread(\"output/stitched_img_1.png\"),\n",
    "                cv2.imread(\"dataset/data_image_stitching/im24.jpg\")]\n",
    "\n",
    "elif data_ix == 3:\n",
    "    nndr_threshold = 0.33\n",
    "    step_size = 0.01\n",
    "    residual_stopping_threshold = 0.02\n",
    "    img_list = [cv2.imread(\"output/stitched_img_2.png\"),\n",
    "                cv2.imread(\"dataset/data_image_stitching/im25.jpg\")]\n",
    "\n",
    "elif data_ix == 4:\n",
    "    nndr_threshold = 0.35\n",
    "    step_size = 0.001\n",
    "    residual_stopping_threshold = 0.1\n",
    "    img_list = [cv2.imread(\"dataset/data_image_stitching/im89.jpg\"),\n",
    "                cv2.imread(\"dataset/data_image_stitching/im90.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8*len(img_list), 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "for i in range(len(img_list)):\n",
    "    plt.subplot(1, len(img_list), i+1)\n",
    "    plt.imshow(cv2.cvtColor(img_list[i], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "keypoints = []\n",
    "descriptors = []\n",
    "img_keypoints = []\n",
    "\n",
    "for img in img_list:\n",
    "    cur_keypoints, cur_descriptors = sift.detectAndCompute(img, None)\n",
    "    keypoints.append(cur_keypoints)\n",
    "    descriptors.append(cur_descriptors)\n",
    "    img_keypoints.append(cv2.drawKeypoints(img, cur_keypoints, None))\n",
    "\n",
    "fig = plt.figure(figsize=(8*len(img_keypoints), 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "for i in range(len(img_keypoints)):\n",
    "    plt.subplot(1, len(img_keypoints), i+1)\n",
    "    plt.imshow(cv2.cvtColor(img_keypoints[i], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_descriptor(descriptor):\n",
    "    return (descriptor - np.min(descriptor)) / (np.max(descriptor) - np.min(descriptor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix(des1, des2):\n",
    "    distance_matrix = np.zeros([des1.shape[0], des2.shape[0]])\n",
    "    for i in range(des1.shape[0]):\n",
    "        dist = np.linalg.norm(descriptors[1] - descriptors[0][i], axis=1)\n",
    "        distance_matrix[i,:] = dist\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eligible_matches(distance_matrix, img1, kp1, des1, img2, kp2, des2, nndr_threshold):\n",
    "    D = np.copy(distance_matrix)\n",
    "    \n",
    "    min_key_points_val = np.min((des1.shape[0], des2.shape[0]))\n",
    "    min_key_points_ind = 1\n",
    "    \n",
    "    min_idx = D.argmin(axis=min_key_points_ind)\n",
    "    min_vals = D.min(axis=min_key_points_ind)\n",
    "    if min_key_points_ind == 1:\n",
    "        D[np.arange(len(D)), min_idx] = np.inf\n",
    "    elif min_key_points_ind == 0:\n",
    "        D[min_idx, np.arange(des2.shape[0])] = np.inf\n",
    "    min_idx2 = D.argmin(axis=min_key_points_ind)\n",
    "    min_vals2 = D.min(axis=min_key_points_ind)\n",
    "    \n",
    "    min_distance = np.concatenate([np.expand_dims(min_vals, axis=0), np.expand_dims(min_vals2, axis=0)], axis=0)\n",
    "    min_indices = np.concatenate([np.expand_dims(min_idx, axis=0), np.expand_dims(min_idx2, axis=0)], axis=0)\n",
    "    \n",
    "    all_matches = [[] for i in range(len(min_idx))]\n",
    "    for i in range(len(min_vals)):\n",
    "        for j in range(2):\n",
    "            all_matches[i].append(cv2.DMatch(i, min_indices[j, i], min_distance[j, i]))\n",
    "    \n",
    "    eligible_matches = []\n",
    "    for i in range(len(min_vals)):\n",
    "        if all_matches[i][0].distance < nndr_threshold * all_matches[i][1].distance:\n",
    "            eligible_matches.append(all_matches[i][0])\n",
    "    \n",
    "    return eligible_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_nndr = True\n",
    "\n",
    "if use_nndr:\n",
    "    distance_matrix = create_distance_matrix(descriptors[0], descriptors[1])\n",
    "    eligible_matches = get_eligible_matches(distance_matrix, img_list[0], keypoints[0], descriptors[0], img_list[1], keypoints[0], descriptors[1], nndr_threshold)\n",
    "    matched_points = [(eligible_matches[i].queryIdx, eligible_matches[i].trainIdx) for i in range(len(eligible_matches))]\n",
    "    matches1to2 = [cv2.DMatch(i, i, 0) for i in range(len(eligible_matches))]\n",
    "\n",
    "else:\n",
    "    number_of_matches = 100\n",
    "    pairwise_distances = scipy.spatial.distance.cdist(normalize_descriptor(descriptors[0]), normalize_descriptor(descriptors[1]))\n",
    "    matched_points = []\n",
    "    for i in range(number_of_matches):\n",
    "        min_index = np.argmin(pairwise_distances)\n",
    "        first_point = min_index // pairwise_distances.shape[1]\n",
    "        second_point = min_index % pairwise_distances.shape[1]\n",
    "        matched_points.append((first_point, second_point))\n",
    "        pairwise_distances[min_index // pairwise_distances.shape[1],:] = np.inf\n",
    "        pairwise_distances[:,min_index % pairwise_distances.shape[1]] = np.inf\n",
    "    matches1to2 = [cv2.DMatch(i, i, 0) for i in range(number_of_matches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_keypoints = []\n",
    "filtered_keypoints.append([keypoints[0][match[0]] for match in matched_points])\n",
    "filtered_keypoints.append([keypoints[1][match[1]] for match in matched_points])\n",
    "img_keypoints = []\n",
    "img_keypoints.append(cv2.drawKeypoints(img_list[0], filtered_keypoints[0], None))\n",
    "img_keypoints.append(cv2.drawKeypoints(img_list[1], filtered_keypoints[1], None))\n",
    "\n",
    "fig = plt.figure(figsize=(8*len(img_keypoints), 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "for i in range(len(img_keypoints)):\n",
    "    plt.subplot(1, len(img_keypoints), i+1)\n",
    "    plt.imshow(cv2.cvtColor(img_keypoints[i], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_img = cv2.drawMatches(img_list[0], filtered_keypoints[0], img_list[1], filtered_keypoints[1], matches1to2, None)\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(cv2.cvtColor(matching_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography(eligible_matches, kp1, kp2, step_size, residual_stopping_threshold):\n",
    "    init_translation = True\n",
    "    max_iteration = 100000\n",
    "    \n",
    "    H = np.random.rand(3, 3).astype(np.float64)\n",
    "    H[0, 0] = 1 + np.random.rand(1, 1)\n",
    "    H[1, 1] = 1 + np.random.rand(1, 1)\n",
    "    H[2, 2] = 1\n",
    "    \n",
    "    E = eligible_matches.copy()\n",
    "    P0 = np.zeros([3, len(E)])\n",
    "    P1 = np.zeros([3, len(E)])\n",
    "    \n",
    "    for i in range(len(E)):\n",
    "        p0 = kp1[E[i].queryIdx]\n",
    "        p1 = kp2[E[i].trainIdx]\n",
    "        P0[:, i] = np.array([p0.pt[0], p0.pt[1], 1])\n",
    "        P1[:, i] = np.array([p1.pt[0], p1.pt[1], 1])\n",
    "    \n",
    "    P0_ravel = P0.transpose()[:, :2].ravel()\n",
    "    P1_ravel = P1.transpose()[:, :2].ravel()\n",
    "    \n",
    "    if init_translation:\n",
    "        arrays = [np.identity(2) for _ in range(len(E))]\n",
    "        J = np.concatenate((arrays), axis=0)\n",
    "        p_star = np.matmul(np.matmul(np.linalg.inv(np.matmul(J.transpose(), J)), J.transpose()), P1_ravel - P0_ravel)\n",
    "        H[0, 2] = p_star[0]\n",
    "        H[1, 2] = p_star[1]\n",
    "    \n",
    "    for step in range(max_iteration):\n",
    "        HP = np.matmul(H, P1)\n",
    "        \n",
    "        HP_homogeneous2cartesian = np.transpose([HP[0, :] / HP[2, :], HP[1, :] / HP[2, :]])\n",
    "        predicted = HP_homogeneous2cartesian.ravel()\n",
    "        res = -P0_ravel + predicted\n",
    "        \n",
    "        if np.abs(np.sum(res)) < residual_stopping_threshold:\n",
    "            break\n",
    "        \n",
    "        J = np.zeros([2 * len(E), 9])\n",
    "        for i in range(len(E)):\n",
    "            J_i = np.zeros([2, 9])\n",
    "            J_i[0, 0] = P1[0, i] / HP[2, i]\n",
    "            J_i[0, 1] = P1[1, i] / HP[2, i]\n",
    "            J_i[0, 2] = P1[2, i] / HP[2, i]\n",
    "            \n",
    "            J_i[1, 3] = P1[0, i] / HP[2, i]\n",
    "            J_i[1, 4] = P1[1, i] / HP[2, i]\n",
    "            J_i[1, 5] = P1[2, i] / HP[2, i]\n",
    "            \n",
    "            J_i[0, 6] = -P1[0, i] * HP[0, i] / (HP[2, i] ** 2)\n",
    "            J_i[0, 7] = -P1[1, i] * HP[0, i] / (HP[2, i] ** 2)\n",
    "            J_i[0, 8] = -P1[2, i] * HP[0, i] / (HP[2, i] ** 2)\n",
    "            \n",
    "            J_i[1, 6] = -P1[0, i] * HP[1, i] / (HP[2, i] ** 2)\n",
    "            J_i[1, 7] = -P1[1, i] * HP[1, i] / (HP[2, i] ** 2)\n",
    "            J_i[1, 8] = -P1[2, i] * HP[1, i] / (HP[2, i] ** 2)\n",
    "            \n",
    "            J[2 * i:2 * i + 2, :] = J_i\n",
    "        \n",
    "        delta_X = np.matmul(np.matmul(np.linalg.inv(np.matmul(J.transpose(), J)), J.transpose()), res)\n",
    "        delta_X_reshaped = delta_X.reshape([3, 3])\n",
    "        \n",
    "        H = H - step_size * delta_X_reshaped\n",
    "        H = H / H[2, 2]\n",
    "    \n",
    "    H = H / H[2, 2]\n",
    "    HP = np.matmul(H, P1)\n",
    "    \n",
    "    HP_homogeneous2cartesian = np.transpose([HP[0, :] / HP[2, :], HP[1, :] / HP[2, :]])\n",
    "    predicted = HP_homogeneous2cartesian.ravel()\n",
    "    res = -P0_ravel + predicted\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_package = False\n",
    "\n",
    "if use_package:\n",
    "    (homography, mask) = cv2.findHomography(np.float32([kp.pt for kp in filtered_keypoints[1]]), \n",
    "                                            np.float32([kp.pt for kp in filtered_keypoints[0]]), \n",
    "                                            cv2.RANSAC, ransacReprojThreshold=3.0)\n",
    "\n",
    "else:\n",
    "    homography = find_homography(eligible_matches, keypoints[0], keypoints[1], step_size, residual_stopping_threshold)\n",
    "\n",
    "height1, width1 = img_list[0].shape[:2]\n",
    "height2, width2 = img_list[1].shape[:2]\n",
    "pts = np.concatenate((np.float32([[0, 0], [0, height1], [width1, height1], [width1, 0]]).reshape(-1, 1, 2), \n",
    "                      cv2.perspectiveTransform(np.float32([[0, 0], [0, height2], [width2, height2], [width2, 0]]).reshape(-1, 1, 2), homography)), \n",
    "                     axis=0)\n",
    "[xmin, ymin] = np.int32(np.min(pts, axis=0).squeeze() - 0.5)\n",
    "[xmax, ymax] = np.int32(np.max(pts, axis=0).squeeze() + 0.5)\n",
    "t = [-xmin, -ymin]\n",
    "ht = np.array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]])\n",
    "\n",
    "stitch_r = np.zeros((ymax - ymin, xmax - xmin, 3)).astype(np.uint8)\n",
    "trans_mat = cv2.invert(ht.dot(homography))[1]\n",
    "for i in range(ymax - ymin):\n",
    "    for j in range(xmax - xmin):\n",
    "        img_i = int((trans_mat[1][0] * j + trans_mat[1][1] * i + trans_mat[1][2]) / (trans_mat[2][0] * j + trans_mat[2][1] * i + trans_mat[2][2]))\n",
    "        img_j = int((trans_mat[0][0] * j + trans_mat[0][1] * i + trans_mat[0][2]) / (trans_mat[2][0] * j + trans_mat[2][1] * i + trans_mat[2][2]))\n",
    "        if img_i >= 0 and img_j >= 0 and img_i < img_list[1].shape[0] and img_j < img_list[1].shape[1]:\n",
    "            stitch_r[i][j] = img_list[1][img_i][img_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(cv2.cvtColor(stitch_r, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_l = np.zeros_like(stitch_r)\n",
    "stitch_l[t[1]:height1 + t[1], t[0]:width1 + t[0]] = img_list[0]\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(cv2.cvtColor(stitch_l, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_mask = np.ones_like(stitch_r, dtype=np.float32)\n",
    "stitch_mask[stitch_r > 0] = 0\n",
    "stitch_mask[stitch_l == 0] = 1\n",
    "start_col = np.min(np.where(stitch_mask == 0)[1])\n",
    "end_col = np.max(np.where(stitch_mask == 0)[1])\n",
    "for i in range(stitch_mask.shape[1]):\n",
    "    col_value = np.ones(stitch_mask[:,i].shape) * (i - start_col) / (end_col - start_col)\n",
    "    col_value[np.logical_and(stitch_r[:,i] > 0, stitch_l[:,i] == 0)] = 1\n",
    "    col_value[np.logical_and(stitch_r[:,i] == 0, stitch_l[:,i] > 0)] = 0\n",
    "    col_value = np.clip(col_value, 0.0, 1.0)\n",
    "    stitch_mask[:,i] = col_value\n",
    "result = np.uint8((stitch_r * stitch_mask) + (stitch_l * (1 - stitch_mask)))\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clipped = result[t[1]:,:]\n",
    "rows, cols = np.where(image_clipped[:, :, 0] != 0)\n",
    "min_row, max_row = min(rows), max(rows) + 1\n",
    "min_col, max_col = min(cols), max(cols) + 1\n",
    "image_clipped = image_clipped[min_row:max_row, min_col:max_col, :]\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(cv2.cvtColor(image_clipped, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(f\"output/stitched_img_{data_ix}.png\", image_clipped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs554",
   "language": "python",
   "name": "cs554"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
