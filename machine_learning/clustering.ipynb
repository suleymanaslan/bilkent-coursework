{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import imageio\n",
    "import glob\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "import time\n",
    "\n",
    "seaborn.set()\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import utils\n",
    "import clustering_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1, dataset2, dataset3 = utils.read_dataset2()\n",
    "dataset1, dataset2, dataset3 = utils.normalize_dataset2(dataset1, dataset2, dataset3)\n",
    "\n",
    "color_list = ['firebrick','darkorange','darkgoldenrod','forestgreen','dodgerblue','blueviolet','magenta', 'black']\n",
    "utils.plot_dataset2(dataset1, dataset2, dataset3, color_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.kmeans(dataset1, k=7, dataname=\"dataset1\", create_anim_file=True, color_list=color_list)\n",
    "display.Image(filename='gif/kmeans_dataset1.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.kmeans(dataset2, k=3, dataname=\"dataset2\", create_anim_file=True, color_list=color_list)\n",
    "display.Image(filename='gif/kmeans_dataset2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.kmeans(dataset3, k=2, dataname=\"dataset3\", create_anim_file=True, color_list=color_list)\n",
    "display.Image(filename='gif/kmeans_dataset3.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clustering_functions.kmeans(dataset1, k=7, dataname=\"dataset1\", create_anim_file=False, print_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clustering_functions.kmeans(dataset2, k=3, dataname=\"dataset2\", create_anim_file=False, print_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clustering_functions.kmeans(dataset3, k=2, dataname=\"dataset3\", create_anim_file=False, print_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.single_linkage(dataset1, nb_of_clusters=7, dataname=\"dataset1\", create_anim_file=True, plot_every_iter=50, color_list=color_list)\n",
    "display.Image(filename='gif/singlelinkage_dataset1.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.single_linkage(dataset2, nb_of_clusters=3, dataname=\"dataset2\", create_anim_file=True, plot_every_iter=20, color_list=color_list)\n",
    "display.Image(filename='gif/singlelinkage_dataset2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.single_linkage(dataset3, nb_of_clusters=2, dataname=\"dataset3\", create_anim_file=True, color_list=color_list)\n",
    "display.Image(filename='gif/singlelinkage_dataset3.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.complete_linkage(dataset1, nb_of_clusters=7, dataname=\"dataset1\", create_anim_file=True, plot_every_iter=50, color_list=color_list)\n",
    "display.Image(filename='gif/completelinkage_dataset1.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.complete_linkage(dataset2, nb_of_clusters=3, dataname=\"dataset2\", create_anim_file=True, plot_every_iter=20, color_list=color_list)\n",
    "display.Image(filename='gif/completelinkage_dataset2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.complete_linkage(dataset3, nb_of_clusters=2, dataname=\"dataset3\", create_anim_file=True, color_list=color_list)\n",
    "display.Image(filename='gif/completelinkage_dataset3.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.group_average(dataset1, nb_of_clusters=7, dataname=\"dataset1\", create_anim_file=True, plot_every_iter=50, color_list=color_list)\n",
    "display.Image(filename='gif/groupaverage_dataset1.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.group_average(dataset2, nb_of_clusters=3, dataname=\"dataset2\", create_anim_file=True, plot_every_iter=20, color_list=color_list)\n",
    "display.Image(filename='gif/groupaverage_dataset2.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions.group_average(dataset3, nb_of_clusters=2, dataname=\"dataset3\", create_anim_file=True, color_list=color_list)\n",
    "display.Image(filename='gif/groupaverage_dataset3.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(dataset, min_pts, eps, create_anim_file=False, dataname=\"data\"):\n",
    "    start_time = time.time()\n",
    "    eps_c = eps * eps\n",
    "\n",
    "    core_point_list = []\n",
    "    for point_index, cur_point in enumerate(dataset):\n",
    "        points_within_eps = 0\n",
    "        for other_point_index, other_point in enumerate(dataset):\n",
    "            if point_index == other_point_index:\n",
    "                continue\n",
    "            if np.square(cur_point - other_point).sum() < eps_c:\n",
    "                points_within_eps += 1\n",
    "            if points_within_eps >= min_pts:\n",
    "                core_point_list.append(point_index)\n",
    "                break\n",
    "\n",
    "    core_points = dataset[core_point_list]\n",
    "    non_core_points = np.delete(dataset, core_point_list, axis=0)\n",
    "\n",
    "    border_point_list = []\n",
    "    for non_core_point_index, non_core_point in enumerate(non_core_points):\n",
    "        for core_point in core_points:\n",
    "            if np.square(non_core_point - core_point).sum() < eps_c:\n",
    "                border_point_list.append(non_core_point_index)\n",
    "                break\n",
    "\n",
    "    border_points = non_core_points[border_point_list]\n",
    "    noise_points = np.delete(non_core_points, border_point_list, axis=0)\n",
    "\n",
    "    cur_cluster = -1\n",
    "    clusters = np.full(len(dataset), cur_cluster)\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    \n",
    "    done = False\n",
    "    i = 0\n",
    "    while not done:\n",
    "         \n",
    "        if create_anim_file and len(unique_clusters) <= 8:\n",
    "            color_arr = [color_list[cluster] for cluster in clusters]\n",
    "            plt.scatter(dataset[:,0], dataset[:,1], c=color_arr)\n",
    "            plt.title(f'{dataname}')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.savefig(f'gif/dbscan/{dataname}/{i:04d}.png')\n",
    "            plt.close()\n",
    "        \n",
    "        \n",
    "        occurence = np.nonzero(clusters[core_point_list] == -1)\n",
    "        if len(occurence[0]) > 0:\n",
    "            core_point_occurence = occurence[0][0]\n",
    "            cur_cluster += 1\n",
    "            clusters[core_point_list[core_point_occurence]] = cur_cluster\n",
    "\n",
    "            core_point = dataset[core_point_list[core_point_occurence]]\n",
    "            other_core_indices = []\n",
    "            for other_point_index, other_point in enumerate(dataset):\n",
    "                if clusters[other_point_index] == -1 and np.square(core_point - other_point).sum() < eps_c:\n",
    "                    clusters[other_point_index] = clusters[core_point_list[core_point_occurence]]\n",
    "                    if other_point_index in core_point_list:\n",
    "                        other_core_indices.append(other_point_index)\n",
    "            for other_core_index in other_core_indices:\n",
    "                new_core_point = dataset[other_core_index]\n",
    "                for other_point_index, other_point in enumerate(dataset):\n",
    "                    if clusters[other_point_index] == -1 and np.square(new_core_point - other_point).sum() < eps_c:\n",
    "                        clusters[other_point_index] = clusters[other_core_index]\n",
    "                        if other_point_index in core_point_list:\n",
    "                            other_core_indices.append(other_point_index)\n",
    "        else:\n",
    "            done = True\n",
    "        \n",
    "        i += 1\n",
    "            \n",
    "    unique_clusters = np.unique(clusters)\n",
    "    squared_errors = 0\n",
    "    for i in unique_clusters:\n",
    "        if i == -1:\n",
    "            continue\n",
    "        cluster_centroid = dataset[clusters == i].mean(axis=0)\n",
    "        squared_error = np.square(dataset[clusters == i] - cluster_centroid).sum()\n",
    "        squared_errors += squared_error\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Sum of squared errors for {dataname} (normalized) with DBSCAN:{squared_errors:.4f}\")\n",
    "    print(f\"DBSCAN for {dataname} took :{end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_anim_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan(dataset1, min_pts=230, eps=0.795, create_anim_file=create_anim_file, dataname=\"dataset1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan(dataset2, min_pts=30, eps=0.4, create_anim_file=create_anim_file, dataname=\"dataset2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan(dataset3, min_pts=45, eps=0.927, create_anim_file=create_anim_file, dataname=\"dataset3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_anim_file:\n",
    "    anim_file = 'gif/dbscan_dataset1.gif'\n",
    "\n",
    "    frames = []\n",
    "    filenames = glob.glob('gif/dbscan/dataset1/*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for i, filename in enumerate(filenames):\n",
    "        frames.append(imageio.imread(filename))\n",
    "    for i in range(3):\n",
    "        frames.append(imageio.imread(filename))\n",
    "\n",
    "    imageio.mimsave(anim_file, frames, 'GIF', fps=2)\n",
    "    \n",
    "anim_file = 'gif/dbscan_dataset1.gif'\n",
    "display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_anim_file:\n",
    "    anim_file = 'gif/dbscan_dataset2.gif'\n",
    "\n",
    "    frames = []\n",
    "    filenames = glob.glob('gif/dbscan/dataset2/*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for i, filename in enumerate(filenames):\n",
    "        frames.append(imageio.imread(filename))\n",
    "    for i in range(3):\n",
    "        frames.append(imageio.imread(filename))\n",
    "\n",
    "    imageio.mimsave(anim_file, frames, 'GIF', fps=2)\n",
    "    \n",
    "anim_file = 'gif/dbscan_dataset2.gif'\n",
    "display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_anim_file:\n",
    "    anim_file = 'gif/dbscan_dataset3.gif'\n",
    "\n",
    "    frames = []\n",
    "    filenames = glob.glob('gif/dbscan/dataset3/*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for i, filename in enumerate(filenames):\n",
    "        frames.append(imageio.imread(filename))\n",
    "    for i in range(3):\n",
    "        frames.append(imageio.imread(filename))\n",
    "\n",
    "    imageio.mimsave(anim_file, frames, 'GIF', fps=2)\n",
    "    \n",
    "anim_file = 'gif/dbscan_dataset3.gif'\n",
    "display.Image(filename=anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
